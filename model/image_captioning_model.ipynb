{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, add, LSTM, Embedding, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset'\n",
    "train_img_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset\\train'\n",
    "val_img_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset\\val'\n",
    "test_img_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset\\test'\n",
    "train_annot_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset\\annotations\\train.json'\n",
    "val_annot_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset\\annotations\\val.json'\n",
    "test_annot_dir = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\VizWiz Dataset\\annotations\\test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(train_annot_dir, 'r') as file:\n",
    "    train_dict = json.load(file)\n",
    "\n",
    "with open(val_annot_dir, 'r') as file:\n",
    "    val_dict = json.load(file)\n",
    "\n",
    "with open(test_annot_dir, 'r') as file:\n",
    "    test_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_mapping = {}\n",
    "\n",
    "for indiv_dict in train_dict['images']:\n",
    "    img_name = indiv_dict['file_name']\n",
    "    img_id = indiv_dict['id']\n",
    "    train_img_mapping[img_name] = img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_mapping = {}\n",
    "\n",
    "for indiv_dict in val_dict['images']:\n",
    "    img_name = indiv_dict['file_name']\n",
    "    img_id = indiv_dict['id']\n",
    "    val_img_mapping[img_name] = img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "validation_set = []\n",
    "\n",
    " # FIGURE OUT A WAY TO USE CUSTOM CONVNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "shape = (HEIGHT, WIDTH, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(neurons, dense_layers, bn, dropouts):\n",
    "  model = Sequential()\n",
    "\n",
    "  for i, nodes in enumerate(neurons):\n",
    "    if i == 0:\n",
    "      model.add(\n",
    "          Conv2D(nodes, (3, 3), input_shape=shape, activation='relu'))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "      if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    else:\n",
    "      model.add(Conv2D(nodes, (3, 3), activation='relu'))\n",
    "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  for i, nodes in enumerate(dense_layers):\n",
    "    model.add(Dense(nodes, activation='relu'))\n",
    "    model.add(Dropout(dropouts[i]))\n",
    "\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer='adam', metrics=[\"accuracy\"])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_aug.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(\n",
    "    X_val, y_val), batch_size=132, epochs=30, callbacks=[es, cp], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5: None -- [Errno 11002] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1037\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m \n\u001b[0;32m   1041\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 975\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1447\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mConnect to a host on a given (SSL) port.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1447\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:941\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mhttp.client.connect\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport)\n\u001b[1;32m--> 941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_connection(\n\u001b[0;32m    942\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address)\n\u001b[0;32m    943\u001b[0m \u001b[39m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:824\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    823\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 824\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m getaddrinfo(host, port, \u001b[39m0\u001b[39;49m, SOCK_STREAM):\n\u001b[0;32m    825\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11002] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:283\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m   urlretrieve(origin, fpath, DLProgbar())\n\u001b[0;32m    284\u001b[0m \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:82\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     80\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m response \u001b[39m=\u001b[39m urlopen(url, data)\n\u001b[0;32m     83\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fd:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[0;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    495\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m     \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11002] getaddrinfo failed>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\source-code\\model\\image_captioning_model.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Define VGG16 Model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m VGG16()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m Model(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39minputs, outputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39moutputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\vgg16.py:212\u001b[0m, in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    211\u001b[0m   \u001b[39mif\u001b[39;00m include_top:\n\u001b[1;32m--> 212\u001b[0m     weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39;49mget_file(\n\u001b[0;32m    213\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mvgg16_weights_tf_dim_ordering_tf_kernels.h5\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    214\u001b[0m         WEIGHTS_PATH,\n\u001b[0;32m    215\u001b[0m         cache_subdir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodels\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    216\u001b[0m         file_hash\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m64373286793e3c8b2b4e3219cbf3544b\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    217\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mget_file(\n\u001b[0;32m    219\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         WEIGHTS_PATH_NO_TOP,\n\u001b[0;32m    221\u001b[0m         cache_subdir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    222\u001b[0m         file_hash\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\data_utils.py:287\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(error_msg\u001b[39m.\u001b[39mformat(origin, e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmsg))\n\u001b[0;32m    286\u001b[0m   \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mURLError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(error_msg\u001b[39m.\u001b[39mformat(origin, e\u001b[39m.\u001b[39merrno, e\u001b[39m.\u001b[39mreason))\n\u001b[0;32m    288\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    289\u001b[0m   \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fpath):\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5: None -- [Errno 11002] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "# Define VGG16 Model\n",
    "model = VGG16()\n",
    "model = Model(input=model.inputs, outputs=model.layers[-2].outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, split_set, set_dict):\n",
    "    image_features = {}\n",
    "    directory = os.path.join(base_dir, split_set)\n",
    "\n",
    "    for img_name in tqdm(os.listdir(directory)):\n",
    "        if not (img_name in set_dict.keys()): continue\n",
    "        # Load an image\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = load_img(img_path, target_size=(HEIGHT, WIDTH))\n",
    "        # Convert image into numpy pixel values\n",
    "        img = img_to_array(img)\n",
    "        # Reshape the data for the model\n",
    "        img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        # Preprocess\n",
    "        img = preprocess_input(img)\n",
    "        # Extract features\n",
    "        feature = model.predict(img, verbose=0)\n",
    "        # Map img_id with its features\n",
    "        img_id = set_dict[img_name]\n",
    "        image_features[img_id] = feature\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 3885/23954 [06:37<34:13,  9.77it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\source-code\\model\\image_captioning_model.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_img_features \u001b[39m=\u001b[39m get_features(model, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, train_img_mapping)\n",
      "\u001b[1;32md:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\source-code\\model\\image_captioning_model.ipynb Cell 11\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(model, split_set, set_dict)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Load an image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, img_name)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m img \u001b[39m=\u001b[39m load_img(img_path, target_size\u001b[39m=\u001b[39;49m(HEIGHT, WIDTH))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Convert image into numpy pixel values\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/University%20Files/Assignments/7th%20Semester/Machine%20Learning/Project/source-code/model/image_captioning_model.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m img \u001b[39m=\u001b[39m img_to_array(img)\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\image_utils.py:443\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    441\u001b[0m       img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mresize(width_height_tuple, resample, box\u001b[39m=\u001b[39mcrop_box)\n\u001b[0;32m    442\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m       img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mresize(width_height_tuple, resample)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:1961\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   1958\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mresize(size, resample, box)\n\u001b[0;32m   1959\u001b[0m     \u001b[39mreturn\u001b[39;00m im\u001b[39m.\u001b[39mconvert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode)\n\u001b[1;32m-> 1961\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1963\u001b[0m \u001b[39mif\u001b[39;00m reducing_gap \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m resample \u001b[39m!=\u001b[39m NEAREST:\n\u001b[0;32m   1964\u001b[0m     factor_x \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m size[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m reducing_gap) \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ammar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n\u001b[0;32m    252\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 253\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    254\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    255\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_img_features = get_features(model, 'train', train_img_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_features = get_features(model, 'val', val_img_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_features_path = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\loaded_data\\train_img_features.pkl'\n",
    "val_img_features_path = r'D:\\University Files\\Assignments\\7th Semester\\Machine Learning\\Project\\loaded_data\\val_img_features.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(train_img_features, train_img_features_path, 'wb')\n",
    "pickle.dump(val_img_features, val_img_features_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_img_features_path, 'rb') as f:\n",
    "    train_img_features = pickle.load(f)\n",
    "with open(val_img_features_path, 'rb') as f:\n",
    "    val_img_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_captions(img_name, dict_set):\n",
    "    img_captions = []\n",
    "    for d in dict_set['images']:\n",
    "        if d.get('file_name') == img_name:\n",
    "            img_id = d.get('id')\n",
    "            for k in dict_set['annotations']:\n",
    "                if k.get('image_id') == img_id:\n",
    "                    if k.get('is_rejected') == False:\n",
    "                        img_captions.append(k.get('caption'))\n",
    "                        \n",
    "    return img_captions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c2737f5cd3eb6a237b7123ce75c641d6f975db18b0c0702ad2055474d78171c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
